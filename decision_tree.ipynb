{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "938fcfca-b26e-4289-8e88-cdd3a57b28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05259d9-232a-4295-8428-7048f4e6853e",
   "metadata": {},
   "source": [
    "- max_depth – максимальная глубина.\n",
    "По-умолчанию: 5\n",
    "- min_samples_split – кол-во объектов в листе, чтобы его можно было разбить и превратить в узел.\n",
    "По-умолчанию: 2\n",
    "- max_leafs – максимальное количество листьев разрешенное для дерева.\n",
    "По-умолчанию: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d183c69-e75e-4915-89d3-7dfd88ac4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth = 5, min_samples_split = 2, max_leafs  = 20):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.leafs_count = 0\n",
    "        self.pred_sum = 0\n",
    "       \n",
    "    def _entropy(self, y):\n",
    "        epsilon = 1e-12\n",
    "        p0 = np.sum(y == 0) / len(y)\n",
    "        p1 = np.sum(y == 1) / len(y)\n",
    "        entropy = - (p0 * np.log2(p0 + epsilon) + p1 * np.log2(p1 + epsilon))\n",
    "        return entropy\n",
    "    def __repr__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "        \n",
    "    def _get_best_split(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_array = X.values\n",
    "            col_names = X.columns\n",
    "        else:\n",
    "             X_array = np.asarray(X)\n",
    "            \n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y_array= y.values.flatten()\n",
    "        else:\n",
    "            y_array = np.asarray(y)\n",
    "        n_samples, n_features = X_array.shape\n",
    "        S_0 = self._entropy(y_array)\n",
    "        max_IG = 0\n",
    "        best_split = None\n",
    "        best_feature_index = None\n",
    "        for j in range(n_features):\n",
    "            f = np.sort(np.unique(X_array[:,j]))\n",
    "            splits = []\n",
    "            for i in range(len(f)-1):\n",
    "                split = (f[i]+f[i+1])/2\n",
    "                mask_left = X_array[:, j] <= split\n",
    "                mask_right = X_array[:, j] > split\n",
    "                X_r, y_r = X_array[mask_right], y_array[mask_right]\n",
    "                X_l, y_l = X_array[mask_left], y_array[mask_left]\n",
    "                S_r = self._entropy(y_r)\n",
    "                S_l = self._entropy(y_l)\n",
    "                N_r = len(y_r)\n",
    "                N_l = len(y_l)\n",
    "                IG = S_0 - N_r / n_samples * S_r - N_l/n_samples * S_l\n",
    "                if IG > max_IG:\n",
    "                    max_IG = IG\n",
    "                    best_split = split\n",
    "                    best_feature_index = j\n",
    "        return best_feature_index, max_IG, best_split,\n",
    "        \n",
    "    def _build_tree(self, X_train, y_train, feature_names, depth = 0):\n",
    "   \n",
    "        if (\n",
    "            depth >= self.max_depth or \n",
    "            len(np.unique(y_train)) == 1 or \n",
    "            len(y_train) == 1 or \n",
    "            len(y_train) < self.min_samples_split or\n",
    "            self.leafs_count>= self.max_leafs\n",
    "        ):\n",
    "            \n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth\n",
    "            }\n",
    "        \n",
    "        best_feature, ig, best_split = self._get_best_split(X_train, y_train)\n",
    "        self.leafs_count += 1\n",
    "        if ig <= 0:\n",
    "    \n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train)\n",
    "            }\n",
    "        mask_left = X_train[:, best_feature] <= best_split\n",
    "        mask_right = X_train[:, best_feature] > best_split\n",
    "        X_r, y_r = X_train[mask_right], y_train[mask_right]\n",
    "        X_l, y_l = X_train[mask_left], y_train[mask_left]\n",
    "        \n",
    "        right_subtree = self._build_tree(X_r, y_r, feature_names, depth +1)\n",
    "        left_subtree = self._build_tree(X_l, y_l, feature_names,depth +1)\n",
    "        return {\n",
    "            \"type\" : \"node\",\n",
    "            'feature' : best_feature,\n",
    "            'split' : best_split,\n",
    "            'feature_name' : feature_names[best_feature],\n",
    "            'depth' : depth,\n",
    "            'leaf_right' : right_subtree,\n",
    "            'leaf_left' : left_subtree,\n",
    "        \n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.leafs_count = 0\n",
    "        feature_names = X.columns.to_list()\n",
    "        X_train = X.to_numpy()\n",
    "        y_train = y.to_numpy()\n",
    "        self.tree_ = self._build_tree(X_train, y_train, feature_names, depth = 0)\n",
    "\n",
    "    def print_tree(self, node = None, path = \"1\", side = None):\n",
    "        if node is None:\n",
    "            node = self.tree_\n",
    "        if node[\"type\"] == \"leaf\":\n",
    "            if side is not None:\n",
    "                print(' '*node['depth'], f\"{path}.{side} - {node[\"prediction\"]}\")\n",
    "            else:\n",
    "                print(f\"{path} - {node[\"prediction\"]}\")\n",
    "            return\n",
    "        feature = node[\"feature_name\"]\n",
    "        split = node[\"split\"]\n",
    "        depth = node['depth']\n",
    "        print(' '*depth, f\"{path} - {feature} > {split}\")\n",
    "        self.print_tree(node[\"leaf_left\"], path + \".1\", side = \"left\") \n",
    "        self.print_tree(node[\"leaf_right\"], path + \".2\", side = \"right\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba74fc9-c8fe-47b8-a00d-3be045fac895",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['variance', 'skewness', 'curtosis', 'entropy', 'class']\n",
    "data = pd.read_csv(\"data_banknote_authentication.txt\", names = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c32fa405-de67-4b72-9a1c-46a9c17b89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"class\", axis = 1)\n",
    "y = data[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9f6e8b6-9e03-4b04-a43c-b3a9af37e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = MyTreeClf( max_depth = 5, min_samples_split = 200, max_leafs  = 10)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb1311f2-3c5b-4635-ae72-8aefd243e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4.796617280208611\n"
     ]
    }
   ],
   "source": [
    "print(tree.leafs_count, tree.pred_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264f3a5-29af-4e32-8fd0-252fbd555b8b",
   "metadata": {},
   "source": [
    "1 - variance > 0.320165\n",
    "\n",
    "1.1 - skewness > 5.86535\n",
    "\n",
    "1.1.1 - curtosis > 6.21865\n",
    "\n",
    "1.1.1.1 - variance > -0.36205\n",
    "\n",
    "1.1.1.1.left - 1.0\n",
    "\n",
    "1.1.1.1.right - 0.9649122807017544\n",
    "\n",
    "1.1.1.right - 0.8397435897435898\n",
    "\n",
    "1.1.right - 0.2867647058823529\n",
    "\n",
    "1.2 - variance > 1.7907000000000002\n",
    "\n",
    "1.2.1 - curtosis > -2.2721999999999998\n",
    "\n",
    "1.2.1.left - 0.9473684210526315\n",
    "\n",
    "1.2.1.right - 0.10227272727272728\n",
    "\n",
    "1.2.2 - curtosis > -4.802\n",
    "\n",
    "1.2.2.2 - variance > 2.03655\n",
    "\n",
    "1.2.2.2.left - 0.05555555555555555\n",
    "\n",
    "1.2.2.2.right - 0.0\n",
    "\n",
    "1.2.2.left - 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "779f6064-5443-4a94-a12e-20073f6f985c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 - variance > 0.320165\n",
      "  1.1 - skewness > 5.86535\n",
      "   1.1.1 - curtosis > 6.21865\n",
      "    1.1.1.1 - variance > -0.36205\n",
      "     1.1.1.1.1.left - 1.0\n",
      "     1.1.1.1.2.right - 0.9649122807017544\n",
      "    1.1.1.2.right - 0.8397435897435898\n",
      "   1.1.2.right - 0.2867647058823529\n",
      "  1.2 - variance > 1.7907000000000002\n",
      "   1.2.1 - curtosis > -2.2721999999999998\n",
      "    1.2.1.1.left - 0.9473684210526315\n",
      "    1.2.1.2.right - 0.10227272727272728\n",
      "   1.2.2 - curtosis > -4.802\n",
      "    1.2.2.1.left - 0.6\n",
      "    1.2.2.2 - variance > 2.03655\n",
      "     1.2.2.2.1.left - 0.05555555555555555\n",
      "     1.2.2.2.2.right - 0.0\n"
     ]
    }
   ],
   "source": [
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "58f5e5f4-5461-4f99-a7fe-acfea062dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# Фиксируем сид для воспроизводимости\n",
    "np.random.seed(42)\n",
    "\n",
    "# Синтетические данные\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_redundant=0,\n",
    "    n_classes=2\n",
    ")\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d6941cf-e4f8-43f3-b4d8-b3d46b2a1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    epsilon = 1e-12\n",
    "    p0 = np.sum(y == 0) / len(y)\n",
    "    p1 = np.sum(y == 1) / len(y)\n",
    "    entropy = - (p0 * np.log2(p0 + epsilon) + p1 * np.log2(p1 + epsilon))\n",
    "    return entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc097df6-e49b-4acd-8f6b-2601a357a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y):\n",
    "    N, n_features = X.shape\n",
    "    S_0 = entropy(y)\n",
    "    max_IG = 0\n",
    "    best_split = 0\n",
    "    feature_index = 0\n",
    "    for j in range(n_features):\n",
    "        f = np.sort(np.unique(X[:,j]))\n",
    "        splits = []\n",
    "        for i in range(len(f)-1):\n",
    "            split = (f[i]+f[i+1])/2\n",
    "            mask_left = X[:, j] <= split\n",
    "            mask_right = X[:, j] > split\n",
    "            X_r, y_r = X[mask_right], y[mask_right]\n",
    "            X_l, y_l = X[mask_left], y[mask_left]\n",
    "            S_r = entropy(y_r)\n",
    "            S_l = entropy(y_l)\n",
    "            N_r = len(y_r)\n",
    "            N_l = len(y_l)\n",
    "            IG = S_0 - N_r / N * S_r - N_l/N * S_l\n",
    "            if IG > max_IG:\n",
    "                max_IG = IG\n",
    "                best_split = split\n",
    "                feature_index = j\n",
    "    return feature_index, max_IG, best_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "585a089b-296f-4320-aa7b-4c566629f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction(y):\n",
    "    unique, counts = np.unique(y, return_counts = True)\n",
    "    max_freq = max(counts)\n",
    "    modes = unique[np.where(counts == max_freq)]\n",
    "    if len(modes) > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return modes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ba9dfee-cf50-4815-a435-899b98d8fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_count = 0\n",
    "pred_sum = 0\n",
    "def build_tree(X_train, y_train, depth = 0, max_depth = 10, min_samples_split = 10, max_leafs = 20):\n",
    "    global leaf_count\n",
    "    global pred_sum\n",
    "    if (\n",
    "        depth >= max_depth or \n",
    "        len(np.unique(y_train)) == 1 or \n",
    "        len(y_train) == 1 or \n",
    "        len(y_train) < min_samples_split or\n",
    "        leaf_count >= max_leafs\n",
    "    ):\n",
    "        leaf_count += 1\n",
    "        pred = np.mean(y_train)\n",
    "        return {\n",
    "            \"type\" : \"leaf\",\n",
    "            \"prediction\" : pred,\n",
    "            \"n_samples\" : len(y_train)\n",
    "        }\n",
    "    \n",
    "    best_feature, ig, best_split = get_best_split(X_train, y_train)\n",
    "    \n",
    "    if ig <= 0:\n",
    "        leaf_count += 1\n",
    "        pred = np.mean(y_train)\n",
    "        return pred\n",
    "        \n",
    "    mask_left = X_train[:, best_feature] <= best_split\n",
    "    mask_right = X_train[:, best_feature] > best_split\n",
    "    X_r, y_r = X_train[mask_right], y_train[mask_right]\n",
    "    X_l,y_l = X_train[mask_left], y_train[mask_left]\n",
    "    right_subtree = build_tree(X_r, y_r, depth +1)\n",
    "    left_subtree = build_tree(X_l, y_l, depth +1)\n",
    "    node = {\n",
    "        \"type\" : \"node\",\n",
    "        'feature' : best_feature,\n",
    "        'split' : best_split,\n",
    "        'leaf_right' : right_subtree,\n",
    "        'leaf_left' : left_subtree,\n",
    "    }\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "713bddd5-eb99-4213-b9b0-07d8e59a8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = build_tree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe654e-e21b-41e4-8cba-f33ef65fab3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
