{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8054a78-196c-40c6-b584-82bf1046c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae7efb2-cc90-42d1-a1a3-1f60c58a65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyForestReg:\n",
    "    def __init__(self, n_estimators = 10, max_features = 0.5, max_samples = 0.5, random_state = 42, max_depth = 5,  min_samples_split = 2, max_leafs = 20, bins = 16, oob_score = None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.oob_score = oob_score\n",
    "        self.leafs_cnt = 0\n",
    "        self.pred_sum = 0\n",
    "        self.trees_ = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"MyForestReg class: n_estimators={self.n_estimators}, max_features= {self.max_features}, \n",
    "        max_samples={self.max_samples},max_depth={self.max_depth}, min_samples_split={self.min_samples_split},\n",
    "        max_leafs={self.max_leafs}\"\"\"\n",
    "        \n",
    "    def _mse(self, y):\n",
    "        y_mean = np.mean(y)\n",
    "        return np.mean((y - y_mean) ** 2)\n",
    "        \n",
    "    def _calculate_oob(self, y_true, y_pred):\n",
    "        \n",
    "        if self.oob_score == \"mae\":\n",
    "            return np.mean(np.abs(y_true - y_pred))\n",
    "        elif self.oob_score == \"mse\":\n",
    "            return np.mean((y_true - y_pred) ** 2)\n",
    "        elif self.oob_score == \"rmse\":\n",
    "            return np.sqrt(np.mean((y_true - y_pred) **2))\n",
    "        elif self.oob_score == \"mape\":\n",
    "            return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        elif self.oob_score == \"r2\":\n",
    "            y_mean = np.mean(y_true)\n",
    "            rss = np.sum((y_true - y_pred) ** 2)\n",
    "            tss = np.sum((y_true - y_mean) ** 2)\n",
    "            return 1 - rss/tss\n",
    "        else:\n",
    "            raise ValueError(\"Неправильная метрика\")\n",
    "        \n",
    "    def _get_best_split(self, X, y):\n",
    "\n",
    "        N, n_features = X.shape\n",
    "        I_p = self._mse(y)\n",
    "        gain = 0\n",
    "        split_value = 0\n",
    "        col_index  = None\n",
    "        for j in range(n_features):\n",
    "            thresholds = self.global_thresholds_[j]\n",
    "            for t in thresholds:\n",
    "                mask_left = X[:, j] <= t\n",
    "                mask_right = X[:, j] > t\n",
    "                if mask_left.sum() == 0 or mask_right.sum() == 0:\n",
    "                    continue\n",
    "                X_r, y_r = X[mask_right], y[mask_right]\n",
    "                X_l, y_l = X[mask_left], y[mask_left]\n",
    "                \n",
    "                I_r, I_l = self._mse(y_r), self._mse(y_l)\n",
    "                N_r, N_l = len(y_r), len(y_l)\n",
    "                \n",
    "                IG = I_p - N_r / N * I_r - N_l/N * I_l\n",
    "                if IG > gain:\n",
    "                    gain = IG\n",
    "                    split_value = t\n",
    "                    col_index = j\n",
    "                        \n",
    "        return col_index, split_value, gain\n",
    "    def _build_tree(self, X_train, y_train, feature_names, depth = 0):\n",
    "        \n",
    "        stop_reasons = []\n",
    "        if depth >= self.max_depth:\n",
    "                stop_reasons.append(\"max_depth\")\n",
    "        \n",
    "        if len(np.unique(y_train)) == 1:\n",
    "            stop_reasons.append(\"pure_node\")\n",
    "    \n",
    "        if len(y_train) == 1:\n",
    "            stop_reasons.append(\"single_sample\")\n",
    "    \n",
    "        if len(y_train) < self.min_samples_split:\n",
    "            stop_reasons.append(\"min_samples_split\")\n",
    "    \n",
    "        if self.potential_leafs >= self.max_leafs:\n",
    "            stop_reasons.append(\"max_leafs\")\n",
    "            \n",
    "        if stop_reasons:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1                      \n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "                }\n",
    "        \n",
    "        best_feature, best_split, ig  = self._get_best_split(X_train, y_train)\n",
    "        \n",
    "        if ig <= 0:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1\n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "            }\n",
    "        n_samples_node = len(y_train)\n",
    "        fn = feature_names[best_feature]\n",
    "        self.fi[fn] += n_samples_node / self.n_samples * ig\n",
    "        self.potential_leafs += 1\n",
    "        \n",
    "        mask_left = X_train[:, best_feature] <= best_split\n",
    "        mask_right = X_train[:, best_feature] > best_split\n",
    "        X_r, y_r = X_train[mask_right], y_train[mask_right]\n",
    "        X_l, y_l = X_train[mask_left], y_train[mask_left]\n",
    "        left_subtree = self._build_tree(X_l, y_l, feature_names,depth +1)\n",
    "        right_subtree = self._build_tree(X_r, y_r, feature_names, depth +1)\n",
    "        \n",
    "        return {\n",
    "            \"type\" : \"node\",\n",
    "            'feature' : best_feature,\n",
    "            'split' : best_split,\n",
    "            'feature_name' : fn,\n",
    "            'depth' : depth,\n",
    "            \"n_samples\" : n_samples_node,\n",
    "            'child_left' : left_subtree,\n",
    "            'child_right' : right_subtree,        \n",
    "        }\n",
    "    def _fit_tree(self, X_train, y_train, feature_names):\n",
    "        \n",
    "        if self.max_leafs < 2:\n",
    "            self.max_leafs = 2    \n",
    "        self.potential_leafs = 1\n",
    "        self.global_thresholds_ = []\n",
    "        for j in range(X_train.shape[1]):\n",
    "            features = X_train[:, j]\n",
    "            f = np.sort(np.unique(features))\n",
    "            native_thresholds = (f[:-1] + f[1:]) / 2 \n",
    "            if self.bins is None:\n",
    "                thresholds = native_thresholds\n",
    "            else:\n",
    "                if self.bins - 1 > len(native_thresholds):\n",
    "                    thresholds = native_thresholds\n",
    "                else:\n",
    "                    thresholds = np.histogram(X_train[:, j], self.bins)[1][1:-1]\n",
    "            self.global_thresholds_.append(thresholds)\n",
    "            \n",
    "        return self._build_tree(X_train, y_train, feature_names, depth = 0)\n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        features = list(X.columns)\n",
    "        X_train, y_train = X.to_numpy(), y.to_numpy()\n",
    "        self.fi = {f : 0 for f in features}\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            cols_idx = random.sample(range(self.n_features), round(self.n_features * self.max_features))\n",
    "            rows_idx = random.sample(range(self.n_samples), round(self.n_samples * self.max_samples))\n",
    "            X_train_sample, y_train_sample = X_train[rows_idx][:, cols_idx], y_train[rows_idx]\n",
    "            selected_features = [features[k] for k in cols_idx]\n",
    "            tree = self._fit_tree(X_train_sample, y_train_sample, selected_features)\n",
    "            self.trees_.append({\n",
    "                \"tree\" : tree,\n",
    "                \"rows\" : rows_idx,\n",
    "                \"cols\" : cols_idx\n",
    "            })\n",
    "\n",
    "        if self.oob_score:\n",
    "            oob_sum = np.zeros(self.n_samples)\n",
    "            oob_count = np.zeros(self.n_samples)\n",
    "            all_idx = np.arange(self.n_samples)\n",
    "            for t in self.trees_:\n",
    "                tree = t[\"tree\"]\n",
    "                rows_idx = t['rows']\n",
    "                cols_idx = t['cols']\n",
    "                oob_idx = np.setdiff1d(all_idx, rows_idx)\n",
    "                X_oob = X_train[oob_idx][:, cols_idx]\n",
    "                oob_preds = np.zeros(X_oob.shape[0])\n",
    "                for i in range(X_oob.shape[0]):\n",
    "                    node = tree\n",
    "                    while node[\"type\"] != \"leaf\":\n",
    "                \n",
    "                        feature_number = node['feature']\n",
    "                        predicat = node['split']\n",
    "                        if X_oob[i, feature_number] <= predicat:\n",
    "                            node = node['child_left']\n",
    "                        else:\n",
    "                            node = node['child_right']\n",
    "                    result = node['prediction']\n",
    "                    oob_preds[i] = result    \n",
    "                oob_sum[oob_idx] += oob_preds\n",
    "                oob_count[oob_idx] += 1\n",
    "            oob_mask = oob_count > 0\n",
    "            oob_pred_mean = oob_sum[oob_mask]/oob_count[oob_mask]\n",
    "            oob_pred_true = y_train[oob_mask]\n",
    "            self.oob_score_ = self._calculate_oob(oob_pred_true, oob_pred_mean)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        features = list(X.columns)\n",
    "        X_test = X.to_numpy()\n",
    "        n_test_samples = X.shape[0]\n",
    "        preds = np.zeros((n_test_samples, len(self.trees_)))\n",
    "        \n",
    "        for t in range(len(self.trees_)):\n",
    "            for i in range(n_test_samples):\n",
    "                tree = self.trees_[t]\n",
    "                node = tree[\"tree\"]\n",
    "                while node[\"type\"] != \"leaf\":\n",
    "                    feature_name = node['feature_name']\n",
    "                    feature_number = features.index(feature_name)\n",
    "                    predicat = node['split']\n",
    "                    if X_test[i, feature_number] <= predicat:\n",
    "                        node = node['child_left']\n",
    "                    else:\n",
    "                        node = node['child_right']\n",
    "                result = node['prediction']\n",
    "                preds[i,t] = result\n",
    "        mean_preds = np.mean(preds, axis = 1)\n",
    "        return mean_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d6215a-0525-4d7e-86b4-2ea7bf76d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_diabetes(as_frame=True)\n",
    "X, y = data['data'], data['target']\n",
    "X,y = pd.DataFrame(X), pd.DataFrame(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02bf1ea-1337-4bc8-8e01-231f6048c286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.045341</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.006206</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>0.125019</td>\n",
       "      <td>0.125198</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>-0.005220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.092564</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.036907</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.016658</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.022517</td>\n",
       "      <td>-0.021788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>0.103003</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.056003</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.084492</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.096197</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.051996</td>\n",
       "      <td>0.079265</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>0.036577</td>\n",
       "      <td>-0.076536</td>\n",
       "      <td>0.141322</td>\n",
       "      <td>0.098648</td>\n",
       "      <td>0.061054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.020218</td>\n",
       "      <td>-0.002228</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
       "211  0.092564 -0.044642  0.036907  0.021872 -0.024960 -0.016658  0.000779   \n",
       "72   0.063504  0.050680 -0.004050 -0.012556  0.103003  0.048790  0.056003   \n",
       "321  0.096197 -0.044642  0.051996  0.079265  0.054845  0.036577 -0.076536   \n",
       "73   0.012648  0.050680 -0.020218 -0.002228  0.038334  0.053174 -0.006584   \n",
       "\n",
       "           s4        s5        s6  \n",
       "287  0.034309  0.032432 -0.005220  \n",
       "211 -0.039493 -0.022517 -0.021788  \n",
       "72  -0.002592  0.084492 -0.017646  \n",
       "321  0.141322  0.098648  0.061054  \n",
       "73   0.034309 -0.005142 -0.009362  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238ac27e-c5f5-492a-b933-f610b847cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = MyForestReg(max_depth = 20, oob_score = 'mae')\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350f35f1-1b3b-4372-94e4-e5517295f286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([165.23206132, 162.68654252, 153.37955927, 202.90971249,\n",
       "       133.11847197, 115.1401591 , 197.87304582, 197.87304582,\n",
       "       164.73678098, 154.42389237, 112.61318474, 157.67002011,\n",
       "        99.45155345, 202.90971249, 120.42519227, 141.78919896,\n",
       "       197.87304582, 202.90971249, 177.3601223 , 198.6607657 ,\n",
       "       186.914134  , 121.36814445,  94.18386114, 198.6607657 ,\n",
       "       148.88922571, 177.65428896, 195.45428896, 163.19254242,\n",
       "        99.27186114, 124.73722197, 169.54580619, 152.99401979,\n",
       "       186.914134  , 189.11729928, 179.16159957, 191.57341392,\n",
       "       141.42619527, 139.03606224, 172.48796594,  94.6808355 ,\n",
       "       112.38082174, 138.04144215, 154.22630536, 163.54969043,\n",
       "       158.80383199, 104.26364136, 115.35282931, 120.85200275,\n",
       "        94.77719448, 175.60131482, 137.95870797, 119.86116265,\n",
       "       167.45087866, 114.62401741, 185.69675829, 142.55634899,\n",
       "       118.14785141, 193.62409903,  94.02166093, 100.62973786,\n",
       "       186.914134  , 186.914134  , 136.59973361, 137.74336512,\n",
       "       152.93344527, 191.57341392, 183.30835249, 180.9865321 ,\n",
       "       124.77685399, 167.41541114, 171.31501916, 198.6607657 ,\n",
       "       184.08129928, 120.43239985, 103.68574393, 176.86053155,\n",
       "       202.90971249, 186.914134  , 166.17052408, 163.48802848,\n",
       "       122.49710886, 113.71668038, 103.63807119,  93.77719448,\n",
       "       104.74709433,  92.13275858,  86.27955345,  87.73516265,\n",
       "       150.39964995, 198.6607657 , 152.79077861, 198.6607657 ,\n",
       "        94.95347653,  92.10473786,  84.38109191, 183.76130393,\n",
       "       202.90971249, 169.07432393, 117.63170971,  96.85241059,\n",
       "       198.6607657 , 139.27441667, 202.90971249, 104.83729496,\n",
       "       173.59008442, 111.66440202, 153.64818307, 148.44013441,\n",
       "       190.78569404, 179.55906377, 160.44969043, 190.67924726,\n",
       "       184.08129928, 197.87304582, 197.87304582, 167.93652915,\n",
       "       172.29511194, 135.63577727, 105.54647653, 188.89484749,\n",
       "       155.59919074, 127.29719306,  98.41779521, 191.57341392,\n",
       "       125.1574908 , 167.69327878, 177.75390726, 123.07968886,\n",
       "       176.90812576, 109.78443016, 155.18791382, 115.43223942,\n",
       "       202.90971249])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10055a2c-a062-4b59-ad35-8f569b33b15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 485.6933047770563,\n",
       " 'sex': 178.3761393714827,\n",
       " 'bmi': 3510.301432951824,\n",
       " 'bp': 1507.9156299722792,\n",
       " 's1': 400.5022095658077,\n",
       " 's2': 101.23669543329737,\n",
       " 's3': 1168.6673792094166,\n",
       " 's4': 830.0066263359143,\n",
       " 's5': 2596.4955855276876,\n",
       " 's6': 996.8079538880509}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa75f30e-8275-49be-b175-74585d01480f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.19009369809075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1a444ed1-2753-40f7-b325-92a5fc11a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth = 5, min_samples_split = 2, max_leafs  = 20, bins = None, criterion = \"entropy\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.leafs_cnt = 0\n",
    "        self.pred_sum = 0\n",
    "        self.potential_leafs = 1\n",
    "        self.bins = bins\n",
    "        self.criterion = criterion\n",
    "        self.fi = {}\n",
    "       \n",
    "    def _entropy(self, y):\n",
    "        epsilon = 1e-12\n",
    "        p0 = np.sum(y == 0) / len(y)\n",
    "        p1 = np.sum(y == 1) / len(y)\n",
    "        entropy = - (p0 * np.log2(p0 + epsilon) + p1 * np.log2(p1 + epsilon))\n",
    "        return entropy\n",
    "\n",
    "    def _gini(self, y):\n",
    "        p0 = np.sum(y==0) / len(y)\n",
    "        p1 = np.sum(y==1) / len(y)\n",
    "        gini = 1 - (p0 ** 2 + p1**2)\n",
    "        return gini\n",
    "\n",
    "    def _calculate_criterion(self, y):\n",
    "        if self.criterion == \"entropy\":\n",
    "            return self._entropy(y)\n",
    "        elif self.criterion == \"gini\":\n",
    "            return self._gini(y)\n",
    "        else:\n",
    "            raise ValueError(\"criterion must be 'entropy' or 'gini'\")\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "        \n",
    "    def _get_best_split(self, X, y):\n",
    "       \n",
    "        N, n_features = X.shape\n",
    "        S_0 = self._calculate_criterion(y)\n",
    "        max_IG = 0\n",
    "        best_split = 0\n",
    "        feature_index = 0\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            thresholds = self.global_thresholds_[j]\n",
    "            for t in thresholds:\n",
    "                mask_left = X[:, j] <= t\n",
    "                mask_right = X[:, j] > t\n",
    "                if mask_left.sum() == 0 or mask_right.sum() == 0:\n",
    "                    continue\n",
    "                X_r, y_r = X[mask_right], y[mask_right]\n",
    "                X_l, y_l = X[mask_left], y[mask_left]\n",
    "                S_r = self._calculate_criterion(y_r)\n",
    "                S_l = self._calculate_criterion(y_l)\n",
    "                N_r = len(y_r)\n",
    "                N_l = len(y_l)\n",
    "                IG = S_0 - N_r / N * S_r - N_l/N * S_l\n",
    "                if IG > max_IG:\n",
    "                    max_IG = IG\n",
    "                    best_split = t\n",
    "                    feature_index = j\n",
    "                        \n",
    "        return feature_index, max_IG, best_split\n",
    "\n",
    "        \n",
    "    def _build_tree(self, X_train, y_train, depth = 0):\n",
    "        \n",
    "        stop_reasons = []\n",
    "        if depth >= self.max_depth:\n",
    "                stop_reasons.append(\"max_depth\")\n",
    "        \n",
    "        if len(np.unique(y_train)) == 1:\n",
    "            stop_reasons.append(\"pure_node\")\n",
    "    \n",
    "        if len(y_train) == 1:\n",
    "            stop_reasons.append(\"single_sample\")\n",
    "    \n",
    "        if len(y_train) < self.min_samples_split:\n",
    "            stop_reasons.append(\"min_samples_split\")\n",
    "    \n",
    "        if self.potential_leafs >= self.max_leafs:\n",
    "            stop_reasons.append(\"max_leafs\")\n",
    "            \n",
    "        if stop_reasons:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1            \n",
    "            impurity = self._calculate_criterion(y_train)           \n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "                }\n",
    "        \n",
    "        best_feature, ig, best_split = self._get_best_split(X_train, y_train)\n",
    "        \n",
    "        if ig <= 0:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1\n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "            }\n",
    "        n_samples_node = len(y_train)\n",
    "        fn = self.feature_names[best_feature]\n",
    "        self.fi[fn] += n_samples_node / self.n_samples * ig\n",
    "        \n",
    "        self.potential_leafs += 1\n",
    "        \n",
    "        mask_left = X_train[:, best_feature] <= best_split\n",
    "        mask_right = X_train[:, best_feature] > best_split\n",
    "        X_r, y_r = X_train[mask_right], y_train[mask_right]\n",
    "        X_l, y_l = X_train[mask_left], y_train[mask_left]\n",
    "        left_subtree = self._build_tree(X_l, y_l, depth +1)\n",
    "        right_subtree = self._build_tree(X_r, y_r, depth +1)\n",
    "        \n",
    "        return {\n",
    "            \"type\" : \"node\",\n",
    "            'feature' : best_feature,\n",
    "            'split' : best_split,\n",
    "            'feature_name' : fn,\n",
    "            'depth' : depth,\n",
    "            \"n_samples\" : n_samples_node,\n",
    "            'leaf_left' : left_subtree,\n",
    "            'leaf_right' : right_subtree,        \n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y, feature_names = None):\n",
    "        if self.max_leafs < 2:\n",
    "            self.max_leafs = 2\n",
    "        self.leafs_count = 0\n",
    "        self.pred_sum = 0\n",
    "        \n",
    "        if feature_names is not None:\n",
    "            self.feature_names = feature_names\n",
    "        else:\n",
    "            self.feature_names = X.columns.to_list()\n",
    "            \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_train = X.to_numpy()\n",
    "        else:\n",
    "            X_train = np.asarray(X)\n",
    "\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y_train = y.to_numpy()\n",
    "        else:\n",
    "            y_train = np.asarray(y)\n",
    "        self.fi = {f : 0 for f in self.feature_names}\n",
    "      \n",
    "        self.n_samples = X.shape[0]\n",
    "        self.global_thresholds_ = []\n",
    "        for j in range(X_train.shape[1]):\n",
    "            features = X_train[:, j]\n",
    "            f = np.sort(np.unique(features))\n",
    "            native_thresholds = (f[:-1] + f[1:]) / 2 \n",
    "            if self.bins is None:\n",
    "                thresholds = native_thresholds\n",
    "            else:\n",
    "                if self.bins >= len(native_thresholds):\n",
    "                    thresholds = native_thresholds\n",
    "                else:\n",
    "                    thresholds = np.histogram(X_train[:, j], self.bins)[1][1:-1]\n",
    "            self.global_thresholds_.append(thresholds)\n",
    "            \n",
    "        self.tree_ = self._build_tree(X_train, y_train, depth = 0)\n",
    "           \n",
    "            \n",
    "    def print_tree(self, node = None, path = \"1\", side = None):\n",
    "        if node is None:\n",
    "            node = self.tree_\n",
    "        if node[\"type\"] == \"leaf\":\n",
    "            if side is not None:\n",
    "                print(' '*node['depth'], f\"{path}.{side} - {node['prediction']}\")\n",
    "            else:\n",
    "                print(f\"{path} - {node['prediction']}\")\n",
    "            return\n",
    "        feature = node[\"feature_name\"]\n",
    "        split = node[\"split\"]\n",
    "        depth = node['depth']\n",
    "        print(' '*depth, f\"{path} - {feature} > {split}\")\n",
    "        self.print_tree(node[\"leaf_left\"], path + \".1\", side = \"left\") \n",
    "        self.print_tree(node[\"leaf_right\"], path + \".2\", side = \"right\")\n",
    "\n",
    "    def predict_proba(self, X, feature_names):\n",
    "       \n",
    "        X_test = X.to_numpy()\n",
    "        n_samples = X.shape[0]\n",
    "        probas = np.zeros(n_samples)\n",
    "        for i in range(n_samples):\n",
    "            node = self.tree_\n",
    "            while node[\"type\"] != \"leaf\":\n",
    "                feature_name = node['feature_name']\n",
    "                feature_number = feature_names.index(feature_name)\n",
    "                predicat = node['split']\n",
    "                if X_test[i, feature_number] <= predicat:\n",
    "                    node = node['leaf_left']\n",
    "                else:\n",
    "                    node = node['leaf_right']\n",
    "            result = node['prediction']\n",
    "            probas[i] = result\n",
    "        return probas\n",
    "        \n",
    "    def predict(self, X, feature_names):\n",
    "        probas = self.predict_proba(X, feature_names)\n",
    "        pred = (probas > 0.5).astype(int)\n",
    "        return pred\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0e484942-50d5-4e0f-97a3-8de70849efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyForestClf:\n",
    "    def __init__(self, n_estimators = 10, max_features = 0.5, max_samples = 0.5, random_state = 42, max_depth = 5,  \n",
    "                 min_samples_split = 2, max_leafs = 20, bins = 16, criterion = \"entropy\"):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.criterion = criterion\n",
    "        self.trees = []\n",
    "        self.leafs_cnt = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"MyForestClf class: n_estimators={self.n_estimators}, max_features= {self.max_features}, \n",
    "        max_samples={self.max_samples},max_depth={self.max_depth}, min_samples_split={self.min_samples_split},\n",
    "        max_leafs={self.max_leafs}, bins={self.bins}, criterion={self.criterion}, random_state={self.random_state}\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.feature_names = list(X.columns)\n",
    "        self.fi = {f : 0 for f in self.feature_names}\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_train = X.to_numpy()\n",
    "        else:\n",
    "            X_train = np.asarray(X)\n",
    "\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y_train = y.to_numpy()\n",
    "        else:\n",
    "            y_train = np.asarray(y)\n",
    "            \n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            tree = MyTreeClf( max_depth = self.max_depth, min_samples_split = self.min_samples_split, \n",
    "                             max_leafs  = self.max_leafs, bins = self.bins, criterion = self.criterion)\n",
    "\n",
    "            cols_idx = random.sample(range(self.n_features), round(self.n_features * self.max_features))\n",
    "            rows_idx = random.sample(range(self.n_samples), round(self.n_samples * self.max_samples))\n",
    "            feature_names_sample = [self.feature_names[k] for k in cols_idx]\n",
    "            print(feature_names_sample, cols_idx)\n",
    "            X_train_sample = X_train[rows_idx][:, cols_idx]\n",
    "            y_train_sample = y_train[rows_idx]\n",
    "\n",
    "            tree.fit(X_train_sample,y_train_sample, feature_names_sample)\n",
    "            self.trees.append({\n",
    "                \"tree\" : tree,\n",
    "                \"cols_idx\" : cols_idx\n",
    "            })\n",
    "            self.leafs_cnt += tree.leafs_cnt\n",
    "            for f, imp in tree.fi.items():\n",
    "                self.fi[f] = imp\n",
    "    def predict(self, X, type_ = \"mean\"):\n",
    "        predictions = np.zeros((X.shape[0], self.n_estimators))\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = self.trees[i][\"tree\"]\n",
    "            tree_features = self.trees[i][\"cols_idx\"]\n",
    "            tree_feature_names = [self.feature_names[k] for k in tree_features]\n",
    "            if type_ == \"mean\":\n",
    "                y_pred = tree.predict_proba(X.iloc[:, tree_features], tree_feature_names)\n",
    "            else:\n",
    "                y_pred = tree.predict(X.iloc[:, tree_features], tree_feature_names)\n",
    "            predictions[:, i] = y_pred\n",
    "        if type_ == \"mean\":\n",
    "            pred = np.mean(predictions, axis = 1)\n",
    "            return (pred > 0.5).astype(int)\n",
    "        else:\n",
    "            ones_count = np.sum(predictions, axis = 1)\n",
    "            return (ones_count >= self.n_estimators / 2).astype(int)\n",
    "    def predict_proba(self, X):\n",
    "        predictions = np.zeros((X.shape[0], self.n_estimators))\n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            tree = self.trees[i][\"tree\"]\n",
    "            tree_features = self.trees[i][\"cols_idx\"]\n",
    "            tree_feature_names = [self.feature_names[k] for k in tree_features]\n",
    "            y_pred = tree.predict_proba(X.iloc[:, tree_features], tree_feature_names)\n",
    "            predictions[:, i] = y_pred\n",
    "        return np.mean(predictions, axis = 1)\n",
    "            \n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eef498a5-6102-421e-b49d-5856206b1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1500, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "\n",
    "X_test, y_test = make_classification(n_samples=30, n_features=14, n_informative=10, random_state=42)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_test = pd.Series(y_test)\n",
    "X_test.columns = [f'col_{col}' for col in X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f8368814-e6d4-45a9-a63b-cab20c19d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = MyForestClf(n_estimators = 6, max_depth = 2, max_features = 0.6, max_samples = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "04aaf8ba-7478-4a53-a17d-5e31d9746095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_10', 'col_1', 'col_0', 'col_4', 'col_3', 'col_9', 'col_2', 'col_5'] [10, 1, 0, 4, 3, 9, 2, 5]\n",
      "['col_11', 'col_12', 'col_4', 'col_10', 'col_9', 'col_1', 'col_0', 'col_2'] [11, 12, 4, 10, 9, 1, 0, 2]\n",
      "['col_1', 'col_9', 'col_8', 'col_3', 'col_2', 'col_7', 'col_10', 'col_6'] [1, 9, 8, 3, 2, 7, 10, 6]\n",
      "['col_6', 'col_3', 'col_2', 'col_5', 'col_9', 'col_10', 'col_12', 'col_13'] [6, 3, 2, 5, 9, 10, 12, 13]\n",
      "['col_4', 'col_12', 'col_3', 'col_1', 'col_10', 'col_13', 'col_2', 'col_11'] [4, 12, 3, 1, 10, 13, 2, 11]\n",
      "['col_3', 'col_6', 'col_7', 'col_0', 'col_2', 'col_4', 'col_1', 'col_10'] [3, 6, 7, 0, 2, 4, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "38bb02b1-0531-48be-adbe-e685d9b33878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_3': 0,\n",
       " 'col_6': 0,\n",
       " 'col_7': 0,\n",
       " 'col_0': 0,\n",
       " 'col_2': 0,\n",
       " 'col_4': 0,\n",
       " 'col_1': 0.16781830692354982,\n",
       " 'col_10': 0.09299362536373647}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.trees[5][\"tree\"].fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2dcba1e2-13bc-4096-8862-93d489034fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_0': 0,\n",
       " 'col_1': 0.16781830692354982,\n",
       " 'col_2': 0,\n",
       " 'col_3': 0,\n",
       " 'col_4': 0,\n",
       " 'col_5': 0.051938347795332004,\n",
       " 'col_6': 0,\n",
       " 'col_7': 0,\n",
       " 'col_8': 0.014794689549743188,\n",
       " 'col_9': 0,\n",
       " 'col_10': 0.09299362536373647,\n",
       " 'col_11': 0,\n",
       " 'col_12': 0,\n",
       " 'col_13': 0}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a34832d2-aa2b-4aa9-b9f5-fd31bb355128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_test, type_ = \"mean\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3f3a7b08-5ddb-468b-8e0f-d80948109af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58682179, 0.60621797, 0.58682179, 0.58682179, 0.17125095,\n",
       "       0.20713492, 0.53580694, 0.68009541, 0.53178064, 0.58682179,\n",
       "       0.53147352, 0.53147352, 0.38785186, 0.17125095, 0.58682179,\n",
       "       0.68009541, 0.68009541, 0.58682179, 0.38785186, 0.28737682,\n",
       "       0.53147352, 0.58682179, 0.68009541, 0.17125095, 0.53147352,\n",
       "       0.53178064, 0.58682179, 0.68009541, 0.68009541, 0.53147352])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ee84ff9c-ffec-414c-ae9d-9cae5e13c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_test, type_ = \"vote\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "00d5fd5b-dfc6-45f5-90ff-6d10af7220d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[326], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dt \u001b[38;5;241m=\u001b[39m MyTreeClf()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[316], line 170\u001b[0m, in \u001b[0;36mMyTreeClf.fit\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m    167\u001b[0m             thresholds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(X_train[:, j], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbins)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_thresholds_\u001b[38;5;241m.\u001b[39mappend(thresholds)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[316], line 119\u001b[0m, in \u001b[0;36mMyTreeClf._build_tree\u001b[0;34m(self, X_train, y_train, depth)\u001b[0m\n\u001b[1;32m    117\u001b[0m X_r, y_r \u001b[38;5;241m=\u001b[39m X_train[mask_right], y_train[mask_right]\n\u001b[1;32m    118\u001b[0m X_l, y_l \u001b[38;5;241m=\u001b[39m X_train[mask_left], y_train[mask_left]\n\u001b[0;32m--> 119\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X_r, y_r, depth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m : best_feature,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaf_right\u001b[39m\u001b[38;5;124m'\u001b[39m : right_subtree,        \n\u001b[1;32m    131\u001b[0m }\n",
      "Cell \u001b[0;32mIn[316], line 120\u001b[0m, in \u001b[0;36mMyTreeClf._build_tree\u001b[0;34m(self, X_train, y_train, depth)\u001b[0m\n\u001b[1;32m    118\u001b[0m X_l, y_l \u001b[38;5;241m=\u001b[39m X_train[mask_left], y_train[mask_left]\n\u001b[1;32m    119\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X_l, y_l, depth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m : best_feature,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaf_right\u001b[39m\u001b[38;5;124m'\u001b[39m : right_subtree,        \n\u001b[1;32m    131\u001b[0m }\n",
      "Cell \u001b[0;32mIn[316], line 97\u001b[0m, in \u001b[0;36mMyTreeClf._build_tree\u001b[0;34m(self, X_train, y_train, depth)\u001b[0m\n\u001b[1;32m     89\u001b[0m     impurity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_criterion(y_train)           \n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleaf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m : pred,\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mlen\u001b[39m(y_train),\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m : depth,\n\u001b[1;32m     95\u001b[0m         }\n\u001b[0;32m---> 97\u001b[0m best_feature, ig, best_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ig \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y_train)\n",
      "Cell \u001b[0;32mIn[316], line 54\u001b[0m, in \u001b[0;36mMyTreeClf._get_best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m X_r, y_r \u001b[38;5;241m=\u001b[39m X[mask_right], y[mask_right]\n\u001b[1;32m     53\u001b[0m X_l, y_l \u001b[38;5;241m=\u001b[39m X[mask_left], y[mask_left]\n\u001b[0;32m---> 54\u001b[0m S_r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m S_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_criterion(y_l)\n\u001b[1;32m     56\u001b[0m N_r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_r)\n",
      "Cell \u001b[0;32mIn[316], line 26\u001b[0m, in \u001b[0;36mMyTreeClf._calculate_criterion\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m     gini \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (p0 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m p1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gini\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_criterion\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entropy(y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt = MyTreeClf()\n",
    "dt.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f453a-4af9-47ab-aedc-62506cb4cf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
