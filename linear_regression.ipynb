{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823a74c7-41a7-4696-90bc-15b6a7acc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0c7ab2-d9ae-4dfb-9c02-578f1705d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    def __init__(self, n_iter = 100, learning_rate = 0.1, metric = None, reg = None, l1_coef = 0, l2_coef = None, sgd_sample = None, random_state = 42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.best_score = None\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "        \n",
    "    def _calculate_metric(self, y_true, y_pred):\n",
    "        if self.metric == None:\n",
    "            return None\n",
    "        y_true = np.array(y_true).flatten()\n",
    "        y_pred = np.array(y_pred).flatten()\n",
    "        \n",
    "        if self.metric == \"mae\":\n",
    "            return np.mean(np.abs(y_true - y_pred))\n",
    "        elif self.metric == \"rmse\":\n",
    "            mse = np.mean((y_pred - y_true) ** 2)\n",
    "            return np.sqrt(mse)\n",
    "        elif self.metric == \"mape\":\n",
    "            return np.mean(np.abs((y_true - y_pred) / y_true)) *100\n",
    "        elif self.metric == \"r2\":\n",
    "            y_mean = np.mean(y_true)\n",
    "            ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "            ss_tot = np.sum((y_true - y_mean) ** 2)\n",
    "            if ss_tot == 0:\n",
    "                metric_value =  0\n",
    "            return  1 - (ss_res / ss_tot)\n",
    "        elif self.metric == \"mse\":\n",
    "            return np.mean((y_true - y_pred) ** 2)\n",
    "        else:\n",
    "            return None\n",
    "    def _get_learning_rate(self, iteration):\n",
    "        if callable(self.learning_rate):\n",
    "            return (float(self.learning_rate(iteration)))\n",
    "        else:\n",
    "            return(float(self.learning_rate))\n",
    "\n",
    "    def fit(self, X, y, verbose = False):\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_array = X.values\n",
    "        else:\n",
    "            X_array = np.asarray(X)\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y_array = y.values.flatten()\n",
    "        else:\n",
    "            y_array = np.asarray(y)\n",
    "            \n",
    "        n_samples, n_features = X_array.shape   \n",
    "        X_array = np.c_[np.ones(n_samples), X_array]\n",
    "        self.weights = np.ones(n_features+1)\n",
    "    \n",
    "        for i in range(1, self.n_iter +1):\n",
    "            lr = self._get_learning_rate(i)\n",
    "            y_pred_full = X_array @ self.weights\n",
    "            errors_full = y_pred_full- y_array\n",
    "            if self.sgd_sample:\n",
    "                if isinstance(self.sgd_sample, int):\n",
    "                    sgd_sample = self.sgd_sample\n",
    "                elif isinstance(self.sgd_sample, float):\n",
    "                    sgd_sample = round(X.shape[0] * self.sgd_sample)\n",
    "                else:\n",
    "                    raise ValueError(\"SGD sample должен быть целым или дробным числом!\")\n",
    "                sample_rows_idx = random.sample(range(X.shape[0]), sgd_sample)\n",
    "                X_train = X_array[sample_rows_idx]\n",
    "                y_train = y_array[sample_rows_idx]\n",
    "                \n",
    "            else:\n",
    "                X_train = X_array.copy()\n",
    "                y_train = y_array.copy()\n",
    "                \n",
    "            y_pred_batch = X_train @ self.weights\n",
    "            errors_batch = y_pred_batch - y_train\n",
    "            n_samples_batch = len(X_train)\n",
    "            \n",
    "            if self.reg:\n",
    "                if self.reg == 'l1':\n",
    "                    mse_loss = np.sum(errors_full **2) / n_samples + self.l1_coef * np.sum(np.abs(self.weights))\n",
    "                    grad = (2/n_samples_batch) * (errors_batch  @ X_train) + self.l1_coef * np.sign(self.weights)\n",
    "                elif reg == 'l2':\n",
    "                    mse_loss = np.sum(errors_full **2) / n_samples + self.l2_coef * np.sum(self.weights ** 2)\n",
    "                    grad = (2/n_samples_batch) * (errors_batch  @ X_train) + self.l2_coef * 2 * self.weights\n",
    "                elif reg == 'elasticnet':\n",
    "                    mse_loss = np.sum(errors_full **2) / n_samples + self.l1_coef * np.sum(np.abs(self.weights)) + (1 - self.l1_coef) * np.sum(self.weights ** 2)\n",
    "                    grad = (2/n_samples_batch) * (errors_batch  @ X_train) + self.l1_coef * np.sign(self.weights) + (1 - self.l1_coef) * 2 * self.weights\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                mse_loss = np.sum(errors_full **2) / n_samples\n",
    "                grad = (2/n_samples_batch) * (errors_batch  @ X_train)\n",
    "                \n",
    "           \n",
    "            self.weights -= lr * grad\n",
    "            if self.metric:\n",
    "                metric_value = self._calculate_metric(y_true = y_array, y_pred = y_pred_full)                                    \n",
    "                \n",
    "            if verbose and i % verbose == 0:\n",
    "                if i == 0:\n",
    "                    print(f\"start | loss: {mse_loss:.2f} | learning rate: {lr}\", f\" {self.metric}|{metric_value}\" if self.metric else \"\")\n",
    "                else:\n",
    "                    print(f\" {i} | loss: {mse_loss:.2f} | learning rate: {lr}\",  f\" {self.metric}|{metric_value}\" if self.metric else \"\")\n",
    "                    \n",
    "        if self.metric:\n",
    "            y_final = X_array @ self.weights\n",
    "            self.best_score = self._calculate_metric(y_array, y_final)\n",
    "    \n",
    "    def get_coef(self):\n",
    "        if self.weights is None:\n",
    "            raise ValueError(\"Модель не обучена. Сначала вызовите fit().\")\n",
    "        return self.weights[1:]\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.best_score\n",
    "            \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_array = X.values\n",
    "        else:\n",
    "            X_array = np.asarray(X)\n",
    "            \n",
    "        n_samples = X_array.shape[0]   \n",
    "        X_array = np.c_[np.ones(n_samples), X_array]\n",
    "        y_pred = X_array @ self.weights\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d8de1ae-1ebc-42b0-871d-e0db1f59d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 | loss: 523.99 | learning rate: 0.01  mae|16.64044728345547\n",
      " 200 | loss: 327.45 | learning rate: 0.01  mae|12.02209550488457\n",
      " 300 | loss: 324.83 | learning rate: 0.01  mae|11.89893978181818\n",
      " 400 | loss: 324.64 | learning rate: 0.01  mae|11.893419996345433\n",
      "11.891543017560846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x_train, y_train = make_regression(n_samples=20000,\n",
    "                                   n_features=5,\n",
    "                                   n_informative=5,\n",
    "                                   noise=15,\n",
    "                                   random_state=42)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "y_train = pd.Series(y_train)\n",
    "x_train.columns = [f'col_{col}' for col in x_train.columns]\n",
    "\n",
    "\n",
    "x_test, y_test = make_regression(n_samples=5,\n",
    "                                   n_features=5,\n",
    "                                   n_informative=2,\n",
    "                                   noise=15,\n",
    "                                   random_state=42)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.Series(y_test)\n",
    "x_test.columns = [f'col_{col}' for col in x_test.columns]\n",
    "\n",
    "\n",
    "a = MyLineReg(metric='mae', n_iter = 400, learning_rate = 0.01, reg = 'l1', l1_coef = 0.5, sgd_sample = 50)\n",
    "a.fit(x_train, y_train, verbose=100)\n",
    "print(a.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bad74-3733-4b91-a222-81dc6620251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
