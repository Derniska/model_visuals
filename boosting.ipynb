{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f774592f-5168-4d07-a66c-5719fdab4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8919069e-5253-4f38-b65d-df90ff7fcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeReg:\n",
    "    def __init__(self, max_depth = 5, min_samples_split = 2, max_leafs = 20, bins = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.leafs_cnt = 0\n",
    "        self.n_samples_ensemble = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "    def _mse(self, y):\n",
    "        y_mean = np.mean(y)\n",
    "        return np.mean((y - y_mean) ** 2)\n",
    "\n",
    "    def _get_best_split(self, X, y):\n",
    "        \n",
    "        N, n_features = X.shape\n",
    "        I_p = self._mse(y)\n",
    "        gain = 0\n",
    "        split_value = 0\n",
    "        col_index  = None\n",
    "        for j in range(n_features):\n",
    "            thresholds = self.global_thresholds_[j]\n",
    "            for t in thresholds:\n",
    "                mask_left = X[:, j] <= t\n",
    "                mask_right = X[:, j] > t\n",
    "                if mask_left.sum() == 0 or mask_right.sum() == 0:\n",
    "                    continue\n",
    "                X_r, y_r = X[mask_right], y[mask_right]\n",
    "                X_l, y_l = X[mask_left], y[mask_left]\n",
    "                \n",
    "                I_r, I_l = self._mse(y_r), self._mse(y_l)\n",
    "                N_r, N_l = len(y_r), len(y_l)\n",
    "                \n",
    "                IG = I_p - N_r / N * I_r - N_l/N * I_l\n",
    "                if IG > gain:\n",
    "                    gain = IG\n",
    "                    split_value = t\n",
    "                    col_index = j\n",
    "                        \n",
    "        return col_index, split_value, gain\n",
    "        \n",
    "    def _build_tree(self, X_train, y_train, feature_names, idx, depth = 0):\n",
    "        \n",
    "        stop_reasons = []\n",
    "        if depth >= self.max_depth:\n",
    "                stop_reasons.append(\"max_depth\")\n",
    "        \n",
    "        if len(np.unique(y_train)) == 1:\n",
    "            stop_reasons.append(\"pure_node\")\n",
    "    \n",
    "        if len(y_train) == 1:\n",
    "            stop_reasons.append(\"single_sample\")\n",
    "    \n",
    "        if len(y_train) < self.min_samples_split:\n",
    "            stop_reasons.append(\"min_samples_split\")\n",
    "    \n",
    "        if self.potential_leafs >= self.max_leafs:\n",
    "            stop_reasons.append(\"max_leafs\")\n",
    "            \n",
    "        if stop_reasons:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1                      \n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "                \"indices\" : idx\n",
    "                }\n",
    "        \n",
    "        best_feature, best_split, ig  = self._get_best_split(X_train, y_train)\n",
    "        \n",
    "        if ig <= 0:\n",
    "            pred = np.mean(y_train)\n",
    "            self.pred_sum += pred\n",
    "            self.leafs_cnt += 1\n",
    "            return {\n",
    "                \"type\" : \"leaf\",\n",
    "                \"prediction\" : pred,\n",
    "                \"n_samples\" : len(y_train),\n",
    "                \"depth\" : depth,\n",
    "                \"indices\" : idx\n",
    "            }\n",
    "        n_samples_node = len(y_train)\n",
    "        fn = feature_names[best_feature]\n",
    "        self.fi[fn] += n_samples_node / self.n_samples_ensemble * ig\n",
    "        self.potential_leafs += 1\n",
    "        \n",
    "        mask_left = X_train[:, best_feature] <= best_split\n",
    "        mask_right = X_train[:, best_feature] > best_split\n",
    "        X_r, y_r = X_train[mask_right], y_train[mask_right]\n",
    "        X_l, y_l = X_train[mask_left], y_train[mask_left]\n",
    "\n",
    "        idx_l = idx[mask_left]\n",
    "        idx_r = idx[mask_right]\n",
    "        \n",
    "        left_subtree = self._build_tree(X_l, y_l, feature_names,  idx_l, depth +1)\n",
    "        right_subtree = self._build_tree(X_r, y_r, feature_names, idx_r, depth +1)\n",
    "        \n",
    "        return {\n",
    "            \"type\" : \"node\",\n",
    "            'feature' : best_feature,\n",
    "            'split' : best_split,\n",
    "            'feature_name' : fn,\n",
    "            'depth' : depth,\n",
    "            \"n_samples\" : n_samples_node,\n",
    "            'leaf_left' : left_subtree,\n",
    "            'leaf_right' : right_subtree,        \n",
    "        }\n",
    "    def fit(self, X, y, n_samples_ensemble, feature_names = None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            feature_names = X.columns.to_list()\n",
    "            X_train = X.to_numpy()\n",
    "        else:\n",
    "            X_train = np.asarray(X)\n",
    "\n",
    "        self.n_samples_ensemble = n_samples_ensemble\n",
    "        \n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y_train = y.to_numpy()\n",
    "        else:\n",
    "            y_train = np.asarray(y)\n",
    "        self.f_names = feature_names\n",
    "        if self.max_leafs < 2:\n",
    "            self.max_leafs = 2\n",
    "        self.pred_sum = 0\n",
    "        self.potential_leafs = 1\n",
    "        n_samples = X.shape[0]\n",
    "        self.fi = {f : 0 for f in feature_names}\n",
    "        \n",
    "        self.global_thresholds_ = []\n",
    "        for j in range(X_train.shape[1]):\n",
    "            features = X_train[:, j]\n",
    "            f = np.sort(np.unique(features))\n",
    "            native_thresholds = (f[:-1] + f[1:]) / 2 \n",
    "            if self.bins is None:\n",
    "                thresholds = native_thresholds\n",
    "            else:\n",
    "                if self.bins - 1 > len(native_thresholds):\n",
    "                    thresholds = native_thresholds\n",
    "                else:\n",
    "                    thresholds = np.histogram(X_train[:, j], self.bins)[1][1:-1]\n",
    "            self.global_thresholds_.append(thresholds)\n",
    "        y_indices = np.arange(len(y_train))    \n",
    "        self.tree_ = self._build_tree(X_train, y_train, feature_names, y_indices, depth = 0)\n",
    "               \n",
    "            \n",
    "    def print_tree(self, node = None, path = \"1\", side = None):\n",
    "        if node is None:\n",
    "            node = self.tree_\n",
    "        if node[\"type\"] == \"leaf\":\n",
    "            if side is not None:\n",
    "                print(' '*node['depth'], f\"{path}.{side} - {node['prediction']}\")\n",
    "            else:\n",
    "                print(f\"{path} - {node['prediction']}\")\n",
    "            return\n",
    "        feature = node[\"feature_name\"]\n",
    "        split = node[\"split\"]\n",
    "        depth = node['depth']\n",
    "        print(' '*depth, f\"{path} - {feature} > {split}\")\n",
    "        self.print_tree(node[\"leaf_left\"], path + \".1\", side = \"left\") \n",
    "        self.print_tree(node[\"leaf_right\"], path + \".2\", side = \"right\")\n",
    "    \n",
    "    def predict(self, X, feature_names = None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            if feature_names is None:\n",
    "                feature_names = X.columns.to_list()\n",
    "            X_test = X.to_numpy()\n",
    "        else:\n",
    "            X_test = np.asarray(X)\n",
    "            if feature_names is None:\n",
    "                feature_names = self.f_names\n",
    "        n_samples = X.shape[0]\n",
    "        preds = np.zeros(n_samples)\n",
    "        for i in range(n_samples):\n",
    "            node = self.tree_\n",
    "            while node[\"type\"] != \"leaf\":\n",
    "                feature_name = node['feature_name']\n",
    "                feature_number = feature_names.index(feature_name)\n",
    "                predicat = node['split']\n",
    "                if X_test[i, feature_number] <= predicat:\n",
    "                    node = node['leaf_left']\n",
    "                else:\n",
    "                    node = node['leaf_right']\n",
    "            result = node['prediction']\n",
    "            preds[i] = result\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84e388fe-722d-4fab-8776-5dcea03b03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBoostReg:\n",
    "    def __init__(self, n_estimators = 10, learning_rate = 0.1, max_depth = 5, \n",
    "                 min_samples_split = 2, max_leafs  = 20, bins = 16, loss = \"MSE\", \n",
    "                 metric = None, max_features = 0.5, max_samples = 0.5, random_state = 42,\n",
    "                 reg = 0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.loss = loss.upper()\n",
    "        self.metric = metric\n",
    "        self.trees = []\n",
    "        self.best_score = None\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.reg = reg\n",
    "        self.leaf_count = 0\n",
    "       \n",
    "        self.np_improve_count = 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"MyBoostReg class: n_estimators={self.n_estimators}, learning_rate={self.learning_rate}, \n",
    "                max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}, \n",
    "                bins={self.bins}\"\"\"\n",
    "    def _calculate_metric(self, y_true, y_pred):\n",
    "        \n",
    "        if self.metric == \"MAE\":\n",
    "            return np.meean(np.abs(y_true - y_pred))\n",
    "        elif self.metric == \"MSE\":\n",
    "            return np.mean((y_true - y_pred) ** 2)\n",
    "        elif self.metric == \"RMSE\":\n",
    "            return np.sqrt(np.mean((y_true - y_pred) **2))\n",
    "        elif self.metric == \"MAPE\":\n",
    "            return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        elif self.metric == \"R2\":\n",
    "            y_mean = np.mean(y_true)\n",
    "            rss = np.sum((y_true - y_pred) ** 2)\n",
    "            tss = np.sum((y_true - y_mean) ** 2)\n",
    "            return 1 - rss/tss\n",
    "        else:\n",
    "            raise ValueError(\"Неправильная метрика\")\n",
    "    def _calculate_loss(self, y_true, y_pred):\n",
    "        if self.loss == \"MSE\":\n",
    "            return np.mean((y_true - y_pred)**2)\n",
    "        elif self.loss == \"MAE\":\n",
    "            return np.mean(np.abs(y_true - y_pred))\n",
    "        else: raise ValueError(\"Неправильный лосс\")\n",
    "\n",
    "    def _update_leaf_predictions(self, node, y_true, y_pred):\n",
    "        if node[\"type\"] == \"leaf\":\n",
    "            indices = node['indices']\n",
    "            y_true_sample = y_true[indices]\n",
    "            y_pred_sample = y_pred[indices]\n",
    "            residuals = y_true_sample - y_pred_sample\n",
    "            if self.loss == \"MSE\":\n",
    "                node['prediction'] = np.mean(residuals) + self.leaf_count * self.reg\n",
    "            elif self.loss == \"MAE\":\n",
    "                node['prediction'] = np.median(residuals) + self.leaf_count * self.reg\n",
    "        else:\n",
    "            self._update_leaf_predictions(node['leaf_left'], y_true, y_pred)\n",
    "            self._update_leaf_predictions(node['leaf_right'], y_true, y_pred)\n",
    "           \n",
    "    def _get_learning_rate(self, iteration):\n",
    "        if callable(self.learning_rate):\n",
    "            return self.learning_rate(iteration)\n",
    "        else:\n",
    "            return self.learning_rate\n",
    "            \n",
    "    def fit(self, X, y, X_eval = None, y_eval = None, early_stopping = None, verbose = None):\n",
    "        random.seed(self.random_state)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.feature_names = list(X.columns)\n",
    "        X_train = X.to_numpy()\n",
    "        y_train = y.to_numpy()\n",
    "        \n",
    "        self.fi = {f : 0 for f in self.feature_names}\n",
    "        if self.loss == \"MSE\":\n",
    "            self.pred_0 = np.mean(y_train)\n",
    "        elif self.loss == \"MAE\":\n",
    "            self.pred_0 = np.median(y_train)\n",
    "        else: raise ValueError(\"Неправильный лосс\")\n",
    "          \n",
    "        predictions = np.full(self.n_samples, self.pred_0)\n",
    "\n",
    "        self.tree_learning_rates = []\n",
    "\n",
    "        use_early_stopping = (\n",
    "           early_stopping is not None and \n",
    "           X_eval is not None and \n",
    "           y_eval is not None\n",
    "        )\n",
    "        if use_early_stopping: \n",
    "            if self.metric == \"R2\":\n",
    "                best_eval_score = 0\n",
    "            else: best_eval_score = np.inf\n",
    "            no_improve_count = 0\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            current_lr = self._get_learning_rate(i + 1)\n",
    "            self.tree_learning_rates.append(current_lr)\n",
    "            if self.loss == \"MSE\":\n",
    "                grad = 2 * (predictions - y_train)\n",
    "               \n",
    "            elif self.loss == \"MAE\":\n",
    "                grad = np.sign(predictions - y_train)\n",
    "         \n",
    "            else: raise ValueError(\"Неправильный лосс\")\n",
    " \n",
    "            cols_idx = random.sample(range(self.n_features), round(self.n_features * self.max_features))\n",
    "            rows_idx = random.sample(range(self.n_samples), round(self.n_samples * self.max_samples))\n",
    "            \n",
    "            X_train_sample = X_train[rows_idx][:, cols_idx]\n",
    "            grad_sample = grad[rows_idx]\n",
    "            feature_names_sample = [self.feature_names[k] for k in cols_idx]\n",
    "            \n",
    "            tree = MyTreeReg(max_depth = self.max_depth, min_samples_split = self.min_samples_split, max_leafs = self.max_leafs, bins = self.bins)\n",
    "            tree.fit(X_train_sample, -grad_sample, self.n_samples, feature_names_sample)\n",
    "                 \n",
    "                \n",
    "            self._update_leaf_predictions(tree.tree_, y_train[rows_idx], predictions[rows_idx])\n",
    "            self.trees.append(tree)\n",
    "            self.leaf_count += tree.leafs_cnt\n",
    "\n",
    "            y_pred_tree = tree.predict(X)\n",
    "            predictions += y_pred_tree * current_lr\n",
    "            if use_early_stopping:\n",
    "                y_pred_eval = self.predict(X_eval)\n",
    "                if self.metric:\n",
    "                    eval_score = self._calculate_metric(y_eval, y_pred_eval)\n",
    "                else:\n",
    "                    eval_score = self._calculate_loss(y_eval, y_pred_eval)\n",
    "                if self.metric == 'R2':\n",
    "                    improve = eval_score > best_eval_score\n",
    "                else:\n",
    "                    improve = eval_score <= best_eval_score\n",
    "                    \n",
    "                if improve:\n",
    "                    best_eval_score = eval_score\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "\n",
    "                if no_improve_count >= early_stopping:\n",
    "                    print(f\"Early stopping: остановка на итерации {i}\")\n",
    "                    self.trees = self.trees[:-early_stopping]\n",
    "                    break\n",
    "                    \n",
    "            loss_t = self._calculate_loss(y_train, predictions)\n",
    "            for item in tree.fi.items():\n",
    "                self.fi[item[0]] += item[1]\n",
    "                \n",
    "            if verbose and i % verbose == 0:\n",
    "                if self.loss == \"MSE\":\n",
    "                    print(f\"{i}. Loss[MSE]: {round(loss_t, 2)}\", f\"|{self.metric}: {self._calculate_metric(y_train, predictions)}\" if self.metric else \"\",\n",
    "                          f\"|eval loss: {eval_score}\" if use_early_stopping else \"\")\n",
    "                elif self.loss == \"MAE\":\n",
    "                    print(f\"{i}. Loss[MAE]: {round(loss_t, 2)}\", f\"|{self.metric}: {self._calculate_metric(y_train, predictions)}\" if self.metric else \"\",\n",
    "                          f\"|eval loss: {eval_score}\" if use_early_stopping else \"\")\n",
    "                else: raise ValueError(\"Неправильный лосс\")\n",
    "        if use_early_stopping: \n",
    "            self.best_score = best_eval_score\n",
    "        else:\n",
    "            if self.metric:\n",
    "                self.best_score = self._calculate_metric(y_train, predictions)\n",
    "            else:\n",
    "                self.best_score = loss_t\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        total_preds =  np.full(X.shape[0], self.pred_0)\n",
    "        for i in range(len(self.trees)):\n",
    "            tree = self.trees[i]\n",
    "            tree_lr = self.tree_learning_rates[i]\n",
    "            pred = tree.predict(X, self.feature_names)\n",
    "            total_preds += tree_lr * pred\n",
    "        return total_preds     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f32a1f-ecb2-41f1-b0b0-f141d2b319c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1500, n_features=14, n_informative=10, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "X_test = np.array([\n",
    "    [-0.24795421,  0.57556193,  0.24889397, -0.42903725, 0.2321945,   0.65863195,\n",
    "     -0.47996815, 0.41687306, -0.29505619, -0.46285629, -1.70478591, 0.99541519,\n",
    "     -0.39115637, -0.51598099],\n",
    "    [ 1.0062508,  -0.51077719,  0.65882024,  0.4249196,  0.35356615, -0.79067364,\n",
    "       2.34030022, 1.67618951,  0.08796428,  0.9104611,  1.6766508,  0.73247653,\n",
    "      -0.22888016, -0.65677036],\n",
    "    [-1.13511942, -0.97918044,  0.51613497, -0.50122901, 0.64391301, 0.43917042,\n",
    "      -0.86673023, -2.13962756, 0.07968098, -0.14346973, -1.02074021, -1.79807836,\n",
    "       1.52988349, 0.20259852],\n",
    "    [-0.54683846, -0.60451386,  0.35833407, -1.85158683, -0.16624207, 0.8720902,\n",
    "      -0.98785807, 0.32762622, 1.74449555, -0.06136604, 0.81854872, 2.67962869,\n",
    "      -2.12864912, 1.27084562],\n",
    "    [ 0.90267814, -2.09818746, -2.91180394, 0.77493611, -0.58684268, 2.1482392,\n",
    "       0.32363247, 1.68266291, 1.32188099, -0.04705854, 2.01919925, -1.99998656,\n",
    "      -1.44464125, -0.02133238],\n",
    "    [ 0.71271203,  1.27886581,  2.28165184, -1.53504025, 0.42544486, 0.18517554,\n",
    "      -1.88315021, 0.43731319, -0.95231638, -0.67699514, -1.88001003, 0.22228986,\n",
    "      -0.61764168, -0.37231905],\n",
    "    [-1.63824566, -0.08857107, -0.17963037, -1.57722837, 0.87172442, -0.51068394,\n",
    "      -0.25959672, -0.50544721, 0.68471485, -1.07695454, -0.85019775, 1.06854956,\n",
    "       0.77913063, 1.2114275],\n",
    "    [ 0.36300428,  0.02979617, -1.53268397, 0.972444, -0.58372213, 1.17653325,\n",
    "      -1.72107752, -1.22499989, -0.64015446, 1.48374391, 0.87278741, -1.08574771,\n",
    "      -1.12859067, -0.35840358],\n",
    "    [ 1.17390093,  1.39104248, -0.28758415, -0.13778586, 0.07310425, -0.9486219,\n",
    "      -1.01803767, 0.4136479, -1.13878294, -0.65389709, -0.83560124, -0.90963217,\n",
    "      -0.2067544, 0.31815933],\n",
    "    [-0.29951504, -1.43135485,  1.29914982, -0.71406512, 0.01252186, 0.16524005,\n",
    "      -1.23570302, 1.4381692, -1.28559911, -1.61584647, 1.17841932, 1.63721164,\n",
    "       0.66754808, -0.17204136],\n",
    "    [ 1.4521177,  -0.2215366,   0.79185931, 0.85246864, -0.58445529, 0.80891927,\n",
    "       0.01414926, -0.29918177, -1.17696211, 1.82054391, -1.2291836, -0.74935769,\n",
    "      -0.57064043, -0.59641141],\n",
    "    [ 0.91260231, -0.34072077, -0.19230318, -0.29251619, 0.59515732, -0.61191305,\n",
    "       0.89862787, -1.03996815, 0.45583768, -0.55605256, 0.67099265, 2.44881231,\n",
    "       0.5446125, 0.11784433],\n",
    "    [ 0.34616582, 0.81432285, -0.11718903, 0.95359495, 1.57861539, -0.01511359,\n",
    "       0.06839386, -0.12536699, -0.19861572, -1.00254196, -0.59216633, -0.65822224,\n",
    "      -2.02503631, 1.53839498],\n",
    "    [-0.75134547, -0.2724269, 0.20713944, 1.47812123, -0.69380442, 2.05124694,\n",
    "       1.52009174, 0.88484258, -1.954593, -0.3103968, -1.48239679, -0.09931434,\n",
    "      -0.23927315, 0.13111932],\n",
    "    [-0.43585735, -0.96775234, 1.21600654, -0.13057546, -0.94277524, -0.60599005,\n",
    "       0.46432056, 1.08326178, 0.5644982, -1.1617513, 0.46133071, -0.30757739,\n",
    "      -0.71932169, 0.55539886],\n",
    "    [-0.71726391, -1.13918212, 0.29658384, 0.6952675, -1.6540355, 0.69843278,\n",
    "      -0.11417027, -0.05261187, -0.30737032, 1.24394192, 1.12728112, 1.10937157,\n",
    "       0.42656791, -0.61014975],\n",
    "    [ 0.87896397, 0.96476989, -0.78235392, 0.24748055, -1.30110927, -0.42963498,\n",
    "       0.48060859, -0.45985926, 1.29998737, 0.96030517, -0.00966442, -0.42898072,\n",
    "       0.85316531, 1.44656329],\n",
    "    [-0.78531792, -1.22988312, -0.64489586, -0.52370428, 1.83413456, 1.17720879,\n",
    "       1.94896311, 0.92590418, -0.80372366, -0.4697298, -1.36579593, -1.77142255,\n",
    "      -0.72943705, 0.73565514],\n",
    "    [-0.69193084, 0.23140635, -1.49828181, -0.17732279, -0.32674459, 1.74085808,\n",
    "       0.48996231, 0.29979617, 0.46496165, 0.22794726, 0.2528928, -0.26288247,\n",
    "       2.33999632, 0.96006087],\n",
    "    [-1.0633545, -1.34799578, 1.2371808, -0.45802518, 0.75950004, -0.90968979,\n",
    "       1.02162476, -1.05005479, -0.60568, -0.03204237, 0.47533493, -0.61677536,\n",
    "      -0.25447608, -1.05598981]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9db3aa65-a69a-4524-aa74-e3aad4bc8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = X.tail(300)\n",
    "y_eval = y.tail(300)\n",
    "X_train = X.iloc[:-300]\n",
    "y_train = y.iloc[:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2b7f88f-2580-44b5-a03e-e527bff635fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Loss[MSE]: 27914.02 |RMSE: 167.07488104018276 \n",
      "1. Loss[MSE]: 22126.04 |RMSE: 148.74825418077944 \n",
      "2. Loss[MSE]: 18846.78 |RMSE: 137.2835689917619 \n",
      "3. Loss[MSE]: 17180.32 |RMSE: 131.0737110760486 \n",
      "4. Loss[MSE]: 15947.66 |RMSE: 126.28404577932763 \n",
      "5. Loss[MSE]: 14857.49 |RMSE: 121.89129599227245 \n",
      "6. Loss[MSE]: 14075.4 |RMSE: 118.63979868883578 \n",
      "7. Loss[MSE]: 13413.24 |RMSE: 115.81555371567671 \n",
      "115.81555371567671\n",
      "CPU times: user 1.19 s, sys: 0 ns, total: 1.19 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb = MyBoostReg( learning_rate = 1.6, n_estimators = 8, max_depth = 5, min_samples_split = 2, max_leafs = 20, bins = 16, \n",
    "                max_samples = 1, max_features = 1, reg = 0.01, metric = \"RMSE\")\n",
    "gb.fit(X_train, y_train, verbose = 1)\n",
    "print(gb.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15a133b-c564-4417-ba7d-d76a9c514e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_0': 1629.0731484255657,\n",
       " 'col_1': 2533.3298525139107,\n",
       " 'col_2': 9716.39290175655,\n",
       " 'col_3': 42207.35337681094,\n",
       " 'col_4': 17164.269130111385,\n",
       " 'col_5': 932.3215024500184,\n",
       " 'col_6': 3719.3150569225645,\n",
       " 'col_7': 31109.543426853976,\n",
       " 'col_8': 1420.5224863703252,\n",
       " 'col_9': 795.1360605012211,\n",
       " 'col_10': 25370.968866817315,\n",
       " 'col_11': 856.6601565233777,\n",
       " 'col_12': 7270.152357979473,\n",
       " 'col_13': 27264.5194643781}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3487b06-876f-491c-83b5-48537d8c5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBoostClf:\n",
    "    def __init__(self, n_estimators = 10, learning_rate = 0.1, max_depth = 3, \n",
    "                 min_samples_split = 2, max_leafs  = 20, bins = 16, metric = None, \n",
    "                max_features = 0.5, max_samples = 0.5, random_state  = 42, reg = 0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.bins = bins\n",
    "        self.trees = []\n",
    "        self.metric = metric\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.random_state = random_state\n",
    "        self.reg = reg\n",
    "        self.n_leaves = 0\n",
    "        self.fi = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"MyBoostReg class: n_estimators={self.n_estimators}, learning_rate={self.learning_rate}, \n",
    "                max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}, \n",
    "                bins={self.bins}\"\"\"\n",
    "        \n",
    "    def _confusion_matrix(self, y_true, y_pred):\n",
    "        pred = np.where(y_pred > 0.5, 1, 0)\n",
    "        \n",
    "        tp = np.sum((y_true == 1) & (pred == 1))\n",
    "        tn = np.sum((y_true == 0) & (pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (pred == 0))\n",
    "        return tp, tn, fp, fn\n",
    "    def _accuracy(self, y_true, y_pred):\n",
    "        tp, tn, fp, fn = self._confusion_matrix(y_true, y_pred) \n",
    "        return (tp + tn) / (tp + tn + fp + fn)\n",
    "    def _precision(self,  y_true, y_pred):\n",
    "        tp, tn, fp, fn = self._confusion_matrix(y_true, y_pred)\n",
    "        return tp / (tp + fp)\n",
    "    def _recall(self,  y_true, y_pred):\n",
    "        tp, tn, fp, fn = self._confusion_matrix(y_true, y_pred)\n",
    "        return tp / (tp + fn)\n",
    "    def _f1(self,  y_true, y_pred):\n",
    "        tp, tn, fp, fn = self._confusion_matrix(y_true, y_pred)\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "        \n",
    "    def _roc_auc(self, y_true, y_pred):\n",
    "        order = np.argsort(y_pred)\n",
    "        y_pred_sorted = y_pred[order]\n",
    "        y_true = y_true[order]\n",
    "        ranks = np.zeros_like(y_pred_sorted, dtype=float)\n",
    "    \n",
    "        i = 0\n",
    "        rank = 1\n",
    "        while i < len(y_pred_sorted):\n",
    "            j = i\n",
    "            while j < len(y_pred_sorted) and y_pred_sorted[i] == y_pred_sorted[j]:\n",
    "                j += 1\n",
    "            avg_rank = (rank+(rank + (j- i) - 1)) / 2\n",
    "            ranks[i:j] = avg_rank\n",
    "            rank += (j-i)\n",
    "            i = j\n",
    "        p = np.sum(y_true == 1)\n",
    "        n = np.sum(y_true == 0)\n",
    "        R_pos = np.sum(ranks[y_true == 1])\n",
    "        auc = (R_pos -p * (p + 1)/ 2) / (p * n)\n",
    "        return auc\n",
    "        \n",
    "    def _calculate_metric(self, y_true, y_pred):\n",
    "         if self.metric == \"accuracy\":\n",
    "            return self._accuracy(y_true, y_pred)\n",
    "         elif self.metric == \"precision\":\n",
    "            return self._precision(y_true, y_pred)\n",
    "         elif self.metric == \"recall\":\n",
    "            return self._recall(y_true, y_pred)\n",
    "         elif self.metric == \"f1\":\n",
    "            return self._f1(y_true, y_pred)\n",
    "         elif self.metric == \"roc_auc\":\n",
    "            return self._roc_auc(y_true, y_pred)\n",
    "         else:\n",
    "            raise ValueError(\"Нет такой метрики!\")      \n",
    "    def _calculate_loss(self, y, p):\n",
    "        eps = 1e-15 \n",
    "        log_loss = - np.mean(y * np.log(p + eps) + (1 - y) * np.log(1-p +eps))\n",
    "        return log_loss\n",
    "        \n",
    "    def _get_learning_rate(self, iteration):\n",
    "        if callable(self.learning_rate):\n",
    "            return self.learning_rate(iteration)\n",
    "        else:\n",
    "            return self.learning_rate        \n",
    "        \n",
    "    def _update_leaf_predictions(self, node, y_true, y_pred):\n",
    "        if node[\"type\"] == \"leaf\":\n",
    "            indices = node['indices']\n",
    "            y_true_sample = y_true[indices]\n",
    "            y_pred_sample = y_pred[indices]\n",
    "            residuals = y_true_sample - y_pred_sample\n",
    "            gamma = np.sum(residuals) / np.sum(y_pred_sample * (1 - y_pred_sample)) + self.n_leaves * self.reg\n",
    "            node['prediction'] = gamma \n",
    "        \n",
    "        else:\n",
    "            self._update_leaf_predictions(node['leaf_left'], y_true, y_pred)\n",
    "            self._update_leaf_predictions(node['leaf_right'], y_true, y_pred)\n",
    "            \n",
    "    def fit(self, X, y, X_eval = None, y_eval = None, early_stopping = None, verbose = None):\n",
    "        random.seed(self.random_state)\n",
    "        eps = 1e-15 \n",
    "        self.feature_names = list(X.columns)\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        X_train = X.to_numpy()\n",
    "        y_train = y.to_numpy()\n",
    "        p0 = np.mean(y_train)\n",
    "        self.pred_0 = np.log(p0 / (1- p0) + eps)\n",
    "        self.fi = {f : 0.0 for f in self.feature_names}\n",
    "        predictions = np.full(self.n_samples, self.pred_0)\n",
    "        self.tree_learning_rates = []\n",
    "        \n",
    "        use_early_stopping = (\n",
    "           early_stopping is not None and \n",
    "           X_eval is not None and \n",
    "           y_eval is not None\n",
    "        )\n",
    "        if use_early_stopping:\n",
    "            if self.metric:\n",
    "                best_eval_score = 0\n",
    "            else:\n",
    "                best_eval_score = np.inf\n",
    "            no_improve_count = 0\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            iteration = i + 1\n",
    "            \n",
    "            current_lr = self._get_learning_rate(iteration)\n",
    "            self.tree_learning_rates.append(current_lr)\n",
    "            \n",
    "            p_pred = 1/ (1 + np.exp(-predictions))\n",
    "            grad = p_pred - y_train\n",
    "\n",
    "            cols_idx = random.sample(range(self.n_features), round(self.n_features * self.max_features))\n",
    "            rows_idx = random.sample(range(self.n_samples), round(self.n_samples * self.max_samples))\n",
    "            \n",
    "            X_train_sample = X_train[rows_idx][:, cols_idx]\n",
    "            grad_sample = grad[rows_idx]\n",
    "            feature_names_sample = [self.feature_names[k] for k in cols_idx]\n",
    "            \n",
    "            tree = MyTreeReg(max_depth = self.max_depth, min_samples_split = self.min_samples_split, max_leafs = self.max_leafs, bins = self.bins)\n",
    "            tree.fit(X_train_sample, -grad_sample, self.n_samples, feature_names_sample)\n",
    "            self._update_leaf_predictions(tree.tree_, y_train[rows_idx], p_pred[rows_idx])\n",
    "            self.n_leaves += tree.leafs_cnt\n",
    "    \n",
    "            self.trees.append(tree)\n",
    "            tree_pred = tree.predict(X)\n",
    "            predictions += tree_pred * current_lr\n",
    "            p_model = 1 / (1 + np.exp(-predictions))\n",
    "            loss = self._calculate_loss(y_train, p_model)\n",
    "\n",
    "            for item in tree.fi.items():\n",
    "                self.fi[item[0]] += item[1]\n",
    "                \n",
    "            if self.metric:\n",
    "                clf_metric = self._calculate_metric(y_train, p_model)\n",
    "                \n",
    "            if use_early_stopping:\n",
    "                y_pred_eval = self.predict_proba(X_eval)\n",
    "                if self.metric:\n",
    "                    eval_score = self._calculate_metric(y_eval, y_pred_eval)\n",
    "                    improve = eval_score > best_eval_score\n",
    "                else:\n",
    "                    eval_score = self._calculate_loss(y_eval, y_pred_eval)\n",
    "                    improve = eval_score <= best_eval_score\n",
    "            \n",
    "                if improve:\n",
    "                    best_eval_score = eval_score\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "                    \n",
    "                if no_improve_count >= early_stopping:\n",
    "                    print(f\"Early stopping: остановка на итерации {i}\")\n",
    "                    self.trees = self.trees[:-early_stopping]\n",
    "                    break\n",
    "                    \n",
    "            if verbose and i % verbose == 0:\n",
    "                print(f\"{i}. Loss: {round(loss, 2)}\", f\": {self.metric}: {clf_metric}\" if self.metric else \"\",\n",
    "                      f\"|eval loss: {eval_score}\" if use_early_stopping else \"\")\n",
    "\n",
    "        if use_early_stopping: \n",
    "            self.best_score = best_eval_score\n",
    "        else:\n",
    "            if self.metric:\n",
    "                self.best_score = self._calculate_metric(y_train, predictions)\n",
    "            else:\n",
    "                self.best_score = loss\n",
    "                    \n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_test = X.to_numpy()\n",
    "            test_features = list(X.columns)\n",
    "        else:\n",
    "            X_test = np.asarray(X)\n",
    "            test_features = self.feature_names\n",
    "        total_preds =  np.full(X_test.shape[0], self.pred_0)\n",
    "        \n",
    "        for i in range(len(self.trees)):\n",
    "            tree_lr = self.tree_learning_rates[i]\n",
    "            tree = self.trees[i]\n",
    "            pred = tree.predict(X_test, test_features)\n",
    "            total_preds += tree_lr * pred\n",
    "        probas =  1 / (1 + np.exp(-total_preds))\n",
    "        return probas\n",
    "        \n",
    "    def predict(self, X):\n",
    "       predict_probas = self.predict_proba(X)\n",
    "       y_pred = (predict_probas >= 0.5).astype(int)\n",
    "       return y_pred\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d1790e6-ef3d-4ab5-9c59-4379bc113b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1500, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75ced202-2f88-455f-b19e-492f42a5fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = make_classification(n_samples=30, n_features=14, n_informative=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06cd33be-d62f-4d8c-9d09-a7b61711896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = X.tail(300)\n",
    "y_eval = y.tail(300)\n",
    "X_train = X.iloc[:-300]\n",
    "y_train = y.iloc[:-300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "88149b7a-8720-44e8-a2be-962d59163afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Loss: 0.66 : f1: 0.6776586974443528 |eval loss: 0.7218045112781954\n",
      "1. Loss: 0.65 : f1: 0.7827145465611686 |eval loss: 0.8070175438596491\n",
      "2. Loss: 0.63 : f1: 0.7479338842975206 |eval loss: 0.7676767676767676\n",
      "Early stopping: остановка на итерации 3\n"
     ]
    }
   ],
   "source": [
    "gbr = MyBoostClf(n_estimators = 20, max_features=0.3, max_samples=0.3, min_samples_split = 2, max_depth = 3, metric = 'f1')\n",
    "gbr.fit(X, y, X_eval, y_eval, 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63a4eb41-a38e-4a23-9cb5-5de277d57701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005333345975363486"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.pred_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30d6cdac-22e4-46f6-90ee-04b4c9148c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbefff40-1a2c-4e80-a752-0d0cab50be72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070175438596491"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a170a61-97b6-4dbf-8451-05b1a0b7aaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.trees[0].leafs_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d0e5451-ed33-49a6-b3dd-3f728d6382fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_0': 0.003024505842456007,\n",
       " 'col_1': 0.026517146387864423,\n",
       " 'col_2': 0.002917065845528964,\n",
       " 'col_3': 0.008408493663290611,\n",
       " 'col_4': 0.0031436331498335426,\n",
       " 'col_5': 0,\n",
       " 'col_6': 0,\n",
       " 'col_7': 0,\n",
       " 'col_8': 0,\n",
       " 'col_9': 0.0010499354993329425,\n",
       " 'col_10': 0.019389246946970466,\n",
       " 'col_11': 0.0005537030288300768,\n",
       " 'col_12': 0.004554867560909502,\n",
       " 'col_13': 0.002774837724111546}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6b3b2-cf48-4d6c-8c70-b4a31e7684dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
